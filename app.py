"""
Flask Web Application - X·∫øp L·ªãch Thi
"""

from flask import Flask, request, jsonify, render_template, send_file
import os
import json
from werkzeug.utils import secure_filename
from scheduler import ExamScheduler, SchedulerConfig, SchedulerResult
from datetime import datetime
import pandas as pd
import math

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # 100MB max

# Th∆∞ m·ª•c l∆∞u tr·ªØ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_FOLDER = os.path.join(BASE_DIR, 'uploads')
RESULT_FOLDER = os.path.join(BASE_DIR, 'results')
RESULT_FOLDER = os.path.join(BASE_DIR, 'results')

# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULT_FOLDER, exist_ok=True)

# File types ƒë∆∞·ª£c ph√©p
ALLOWED_EXTENSIONS = {'xlsx', 'xls'}

# Mapping file types
FILE_TYPES = {
    'lhp': 'danhsachLHP.xlsx',
    'data': 'Data.xlsx', 
    'cfg': 'cau_hinh.xlsx',
    'sv': 'danhsachSV.xlsx'
}


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS





@app.route('/')
def index():
    return render_template('index.html')


@app.route('/api/upload', methods=['POST'])
def upload_files():
    """Upload file Excel"""
    if 'file' not in request.files:
        return jsonify({'success': False, 'error': 'Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c g·ª≠i'})
    
    file = request.files['file']
    file_type = request.form.get('type', '')
    
    if file.filename == '':
        return jsonify({'success': False, 'error': 'T√™n file tr·ªëng'})
    
    if not allowed_file(file.filename):
        return jsonify({'success': False, 'error': 'ƒê·ªãnh d·∫°ng file kh√¥ng h·ª£p l·ªá'})
    
    # L∆∞u v·ªõi t√™n chu·∫©n ho·∫∑c t√™n g·ªëc
    if file_type in FILE_TYPES:
        filename = FILE_TYPES[file_type]
    else:
        filename = secure_filename(file.filename)
    
    filepath = os.path.join(UPLOAD_FOLDER, filename)
    file.save(filepath)
    
    return jsonify({
        'success': True,
        'filename': filename,
        'size': os.path.getsize(filepath)
    })


@app.route('/api/files', methods=['GET'])
def get_files():
    """L·∫•y danh s√°ch files ƒë√£ upload"""
    files = {}
    for file_type, filename in FILE_TYPES.items():
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        if os.path.exists(filepath):
            files[file_type] = {
                'filename': filename,
                'size': os.path.getsize(filepath),
                'modified': datetime.fromtimestamp(os.path.getmtime(filepath)).isoformat()
            }
        else:
            files[file_type] = None
    
    return jsonify({'success': True, 'files': files})





@app.route('/api/solve', methods=['POST'])
def solve():
    """Ch·∫°y solver x·∫øp l·ªãch"""
    # Ki·ªÉm tra files
    missing_files = []
    for file_type, filename in FILE_TYPES.items():
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        if not os.path.exists(filepath):
            missing_files.append(filename)
    
    if missing_files:
        return jsonify({
            'success': False,
            'error': f'Thi·∫øu c√°c file: {", ".join(missing_files)}'
        })
    
    # Config m·∫∑c ƒë·ªãnh (ƒë√£ lo·∫°i b·ªè t√πy ch·ªânh)
    config = SchedulerConfig(
        max_to_per_ca=68,
        sv_khong_trung_ca=True,
        ctdt_khong_trung_ngay=True,
        ctdt_khong_lien_ngay=True,
        he_so_penalty_lien_ngay=10,
        solver_timeout=300, # TƒÉng timeout m·∫∑c ƒë·ªãnh
        num_workers=8,
        distribute_uniformly=True # Lu√¥n b·∫≠t load balancing
    )
    
    # Kh·ªüi t·∫°o scheduler
    scheduler = ExamScheduler(config)
    
    # Load data
    load_result = scheduler.load_data(
        path_lhp=os.path.join(UPLOAD_FOLDER, FILE_TYPES['lhp']),
        path_data=os.path.join(UPLOAD_FOLDER, FILE_TYPES['data']),
        path_cfg=os.path.join(UPLOAD_FOLDER, FILE_TYPES['cfg']),
        path_sv=os.path.join(UPLOAD_FOLDER, FILE_TYPES['sv'])
    )
    
    if not load_result['success']:
        return jsonify({
            'success': False,
            'error': f'L·ªói ƒë·ªçc d·ªØ li·ªáu: {load_result.get("error", "Unknown")}'
        })
    
    # Solve
    result = scheduler.solve()
    
    if result.error:
        return jsonify({
            'success': False,
            'status': result.status,
            'error': result.error,
            'data_stats': load_result['stats']
        })
    
    # Export k·∫øt qu·∫£
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_filename = f'ket_qua_xep_lich_{timestamp}.xlsx'
    output_path = os.path.join(RESULT_FOLDER, output_filename)
    
    export_result = scheduler.export_to_excel(result, output_path)
    
    # Export danh s√°ch sinh vi√™n thi
    sv_filename = f'BangTongHopLichThiSinhVien_{timestamp}.xlsx'
    sv_path = os.path.join(RESULT_FOLDER, sv_filename)
    sv_export_result = scheduler.export_student_list(result, sv_path)
    
    return jsonify({
        'success': True,
        'status': result.status,
        'result_file': output_filename,
        'student_file': sv_filename if sv_export_result.get('success') else None,
        'num_records': len(result.records),
        'num_student_records': sv_export_result.get('total_rows', 0),
        'num_violations': export_result.get('num_violations', 0),
        'data_stats': load_result['stats'],
        'solver_stats': result.stats,
        'records': result.records[:500]  # Gi·ªõi h·∫°n 500 d√≤ng ƒë·ªÉ tr√°nh qu√° t·∫£i
    })


@app.route('/api/download/<filename>')
def download_file(filename):
    """T·∫£i xu·ªëng file k·∫øt qu·∫£"""
    filepath = os.path.join(RESULT_FOLDER, secure_filename(filename))
    if os.path.exists(filepath):
        return send_file(filepath, as_attachment=True)
    return jsonify({'success': False, 'error': 'File kh√¥ng t·ªìn t·∫°i'})


# ==========================================
# HELPER: Sync Student File After Schedule Update
# ==========================================
def sync_student_file():
    """C·∫≠p nh·∫≠t BangTongHopLichThiSinhVien_KetQua.xlsx khi l·ªãch thi thay ƒë·ªïi"""
    try:
        schedule_path = os.path.join(BASE_DIR, 'ket_qua_xep_lich_thi.xlsx')
        sv_file_path = os.path.join(BASE_DIR, 'BangTongHopLichThiSinhVien_KetQua.xlsx')
        
        if not os.path.exists(sv_file_path):
            print("   ‚ö†Ô∏è BangTongHopLichThiSinhVien_KetQua.xlsx ch∆∞a t·ªìn t·∫°i, b·ªè qua sync.")
            return
        
        if not os.path.exists(schedule_path):
            print("   ‚ö†Ô∏è ket_qua_xep_lich_thi.xlsx ch∆∞a t·ªìn t·∫°i, b·ªè qua sync.")
            return
        
        # Load files
        df_sv = pd.read_excel(sv_file_path)
        df_schedule = pd.read_excel(schedule_path)
        
        # Normalize column names for matching
        # Student file uses "M√£ HP", "T·ªï thi" vs schedule uses "MaHP", "ToThi"
        # Map schedule columns
        schedule_map = {}
        for _, row in df_schedule.iterrows():
            mahp = str(row.get('MaHP', '')).strip()
            tothi = int(row.get('ToThi', 0)) if pd.notna(row.get('ToThi')) else 0
            key = (mahp, tothi)
            schedule_map[key] = {
                'Ng√†y thi': row.get('Ngay', ''),
                'Gi·ªù thi': row.get('GioThi', '') if 'GioThi' in df_schedule.columns else '',
                'Ph√≤ng thi': row.get('PhongThi', ''),
                'Ca': row.get('Ca', '')
            }
        
        # Map Ca to Gio
        CA_TO_GIO = {1: "07:00", 2: "09:30", 3: "13:00", 4: "15:30"}
        
        # Update student file
        updated_count = 0
        for idx, row in df_sv.iterrows():
            mahp = str(row.get('M√£ HP', '')).strip()
            tothi = int(row.get('T·ªï thi', 0)) if pd.notna(row.get('T·ªï thi')) else 0
            key = (mahp, tothi)
            
            if key in schedule_map:
                new_data = schedule_map[key]
                if 'Ng√†y thi' in df_sv.columns:
                    df_sv.at[idx, 'Ng√†y thi'] = new_data['Ng√†y thi']
                if 'Ph√≤ng thi' in df_sv.columns:
                    df_sv.at[idx, 'Ph√≤ng thi'] = new_data['Ph√≤ng thi']
                if 'Gi·ªù thi' in df_sv.columns:
                    gio = new_data['Gi·ªù thi']
                    if not gio and new_data['Ca']:
                        gio = CA_TO_GIO.get(int(new_data['Ca']), '')
                    df_sv.at[idx, 'Gi·ªù thi'] = gio
                updated_count += 1
        
        # Save updated student file
        df_sv.to_excel(sv_file_path, index=False)
        print(f"   ‚úÖ Synced {updated_count} rows to BangTongHopLichThiSinhVien_KetQua.xlsx")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è Error syncing student file: {e}")

# ==========================================
# SCHEDULE VISUALIZATION & EDITING APIs
# ==========================================

@app.route('/api/schedule/data', methods=['GET'])
def get_schedule_data():
    """L·∫•y d·ªØ li·ªáu l·ªãch thi ƒë·ªÉ hi·ªÉn th·ªã"""
    try:
        # File paths
        schedule_path = os.path.join(BASE_DIR, 'ket_qua_xep_lich_thi.xlsx')
        config_path = os.path.join(BASE_DIR, 'cau_hinh.xlsx') # Ho·∫∑c file c·∫•u h√¨nh upload

        if not os.path.exists(schedule_path):
            return jsonify({'success': False, 'error': 'Ch∆∞a c√≥ d·ªØ li·ªáu l·ªãch thi. Vui l√≤ng x·∫øp l·ªãch tr∆∞·ªõc.'})
        
        # Load Result
        df_sche = pd.read_excel(schedule_path)
        # Clean data (convert NaN to None/Empty)
        df_sche = df_sche.where(pd.notnull(df_sche), None)
        
        # Load Config (Rooms, Days, Shifts)
        if os.path.exists(config_path):
            df_rooms = pd.read_excel(config_path, sheet_name='PhongThi')
            rooms = df_rooms['PhongThi'].dropna().unique().tolist()
            
            # Days from Config or from Result? Better from Result to be safe
            # But we need full list of available slots
            df_time = pd.read_excel(config_path, sheet_name='ThoiGianThi')
            available_days = df_time[df_time['SuDung'] == 1]['NgayThi'].dt.strftime('%d/%m/%Y').tolist()
            
            df_ca = pd.read_excel(config_path, sheet_name='CaThi')
            shifts = df_ca['Ca'].dropna().unique().tolist()
        else:
            # Fallback if config missing
            rooms = df_sche['PhongThi'].unique().tolist()
            available_days = df_sche['Ngay'].unique().tolist()
            shifts = [1, 2, 3, 4]

        # Structure data
        records = df_sche.to_dict('records')
        
        return jsonify({
            'success': True,
            'rooms': sorted(rooms),
            'days': available_days,
            'shifts': sorted(shifts),
            'schedule': records
        })

    except Exception as e:
        print(f"Error loading schedule: {e}")
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/schedule/update', methods=['POST'])
def update_schedule():
    """C·∫≠p nh·∫≠t l·ªãch thi (Move/Swap)"""
    try:
        data = request.json
        # data format: 
        # { 
        #   "action": "move" | "swap", 
        #   "source": { "MaHP": "...", "ToThi": 1, "Ngay": "...", "Ca": 1, "PhongThi": "..." },
        #   "target": { "Ngay": "...", "Ca": 1, "PhongThi": "..." } 
        # }
        
        schedule_path = os.path.join(BASE_DIR, 'ket_qua_xep_lich_thi.xlsx')
        if not os.path.exists(schedule_path):
            return jsonify({'success': False, 'error': 'File l·ªãch thi kh√¥ng t·ªìn t·∫°i'})
            
        df = pd.read_excel(schedule_path)
        
        action = data.get('action')
        source = data.get('source')
        target = data.get('target') # Target slot (Ngay, Ca, PhongThi)
        
        if not source or not target:
            return jsonify({'success': False, 'error': 'Thi·∫øu th√¥ng tin source/target'})

        # T√¨m source row index
        source_idx = df[
            (df['MaHP'] == source['MaHP']) & 
            (df['ToThi'] == source['ToThi'])
        ].index
        
        if len(source_idx) == 0:
             return jsonify({'success': False, 'error': 'Kh√¥ng t√¨m th·∫•y m√¥n h·ªçc ngu·ªìn'})
        
        source_idx = source_idx[0]
        
        # Check if target slot is occupied
        target_idx = df[
            (df['Ngay'] == target['Ngay']) & 
            (df['Ca'] == int(target['Ca'])) & 
            (df['PhongThi'] == target['PhongThi'])
        ].index
        
        if len(target_idx) > 0:
            target_idx = target_idx[0]
            # Target occupied -> SWAP or ERROR?
            # User wants to "ƒë·ªïi l·ªãch cho nhau" => Swap
            
            # Update target row to source values
            df.at[target_idx, 'Ngay'] = source['Ngay']
            df.at[target_idx, 'Ca'] = int(source['Ca'])
            df.at[target_idx, 'PhongThi'] = source['PhongThi']
            
            msg = "ƒê√£ ho√°n ƒë·ªïi l·ªãch thi th√†nh c√¥ng"
        else:
            msg = "ƒê√£ chuy·ªÉn l·ªãch thi th√†nh c√¥ng"

        # Update source row to target values
        df.at[source_idx, 'Ngay'] = target['Ngay']
        df.at[source_idx, 'Ca'] = int(target['Ca'])
        df.at[source_idx, 'PhongThi'] = target['PhongThi']
        
        # Save back to Excel
        df.to_excel(schedule_path, index=False)
        
        # Sync changes to student file
        sync_student_file()
        
        return jsonify({'success': True, 'message': msg})

    except Exception as e:
        print(f"Error updating schedule: {e}")
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/schedule/batch-update', methods=['POST'])
def batch_update_schedule():
    """Batch update: Move multiple exam groups to a target day/shift with conflict checking"""
    try:
        data = request.json
        # data format:
        # {
        #   "items": [{ "MaHP": "...", "ToThi": 1 }, ...],
        #   "target": { "Ngay": "...", "Ca": 1 },
        #   "force_move": false  # If true, bypass same-day warning
        # }
        
        schedule_path = os.path.join(BASE_DIR, 'ket_qua_xep_lich_thi.xlsx')
        config_path = os.path.join(UPLOAD_FOLDER, 'cau_hinh.xlsx')
        sv_path = os.path.join(UPLOAD_FOLDER, 'danhsachSV.xlsx')
        
        if not os.path.exists(schedule_path):
            return jsonify({'success': False, 'error': 'Schedule file not found'})
            
        df_schedule = pd.read_excel(schedule_path)
        
        items = data.get('items', [])
        target = data.get('target', {})
        force_move = data.get('force_move', False)
        
        if not items or not target:
            return jsonify({'success': False, 'error': 'Missing items or target'})
        
        target_day = target.get('Ngay')
        target_shift = int(target.get('Ca'))
        
        # === CONFLICT CHECK ===
        # Load student list to check conflicts
        if os.path.exists(sv_path):
            df_sv = pd.read_excel(sv_path)
            df_sv['MaSV'] = df_sv['MaSV'].astype(str).str.strip()
            df_sv['MaHP'] = df_sv['MaHP'].astype(str).str.strip()
            
            # Build map: MaSV -> list of MaHP they take
            sv_to_mahp = df_sv.groupby('MaSV')['MaHP'].apply(list).to_dict()
            
            # Get students in items being moved with their ToThi
            moving_info = {item['MaHP']: item['ToThi'] for item in items}
            moving_mahps = list(moving_info.keys())
            students_in_moving = df_sv[df_sv['MaHP'].isin(moving_mahps)][['MaSV', 'MaHP']].drop_duplicates()
            
            # Get exams already in target slot (same day, same shift)
            exams_same_shift_df = df_schedule[
                (df_schedule['Ngay'] == target_day) & 
                (df_schedule['Ca'] == target_shift) &
                (~df_schedule['MaHP'].isin(moving_mahps))
            ][['MaHP', 'ToThi']]
            exams_same_shift = set(exams_same_shift_df['MaHP'].unique())
            
            # Get exams on same day (any shift)
            exams_same_day_df = df_schedule[
                (df_schedule['Ngay'] == target_day) &
                (~df_schedule['MaHP'].isin(moving_mahps))
            ][['MaHP', 'ToThi', 'Ca']]
            exams_same_day = set(exams_same_day_df['MaHP'].unique())
            
            # Check for SAME-SHIFT conflicts (HARD BLOCK)
            conflict_details_shift = []
            for _, row in students_in_moving.iterrows():
                masv = row['MaSV']
                moving_mahp = row['MaHP']
                moving_to = moving_info[moving_mahp]
                
                # Check if this student has other exams in target shift
                student_other_mahps = [m for m in sv_to_mahp.get(masv, []) if m in exams_same_shift]
                for conflict_mahp in student_other_mahps:
                    conflict_to = exams_same_shift_df[exams_same_shift_df['MaHP'] == conflict_mahp]['ToThi'].values
                    conflict_to = int(conflict_to[0]) if len(conflict_to) > 0 else '?'
                    conflict_details_shift.append({
                        'MaSV': masv,
                        'moving_MaHP': moving_mahp,
                        'moving_ToThi': moving_to,
                        'conflict_MaHP': conflict_mahp,
                        'conflict_ToThi': conflict_to
                    })
            
            if conflict_details_shift:
                # Limit to 15 entries
                return jsonify({
                    'success': False,
                    'error_type': 'CONFLICT_SHIFT',
                    'error': f'Cannot move! {len(conflict_details_shift)} conflict(s) in same shift.',
                    'conflict_details': conflict_details_shift[:15]
                })
            
            # Check for SAME-DAY conflicts (SOFT WARNING)
            if not force_move:
                conflict_details_day = []
                for _, row in students_in_moving.iterrows():
                    masv = row['MaSV']
                    moving_mahp = row['MaHP']
                    moving_to = moving_info[moving_mahp]
                    
                    student_other_mahps = [m for m in sv_to_mahp.get(masv, []) if m in exams_same_day]
                    for conflict_mahp in student_other_mahps:
                        conflict_row = exams_same_day_df[exams_same_day_df['MaHP'] == conflict_mahp].iloc[0] if len(exams_same_day_df[exams_same_day_df['MaHP'] == conflict_mahp]) > 0 else None
                        if conflict_row is not None:
                            conflict_details_day.append({
                                'MaSV': masv,
                                'moving_MaHP': moving_mahp,
                                'moving_ToThi': moving_to,
                                'conflict_MaHP': conflict_mahp,
                                'conflict_ToThi': int(conflict_row['ToThi']),
                                'conflict_Ca': int(conflict_row['Ca'])
                            })
                
                if conflict_details_day:
                    return jsonify({
                        'success': False,
                        'error_type': 'WARNING_SAME_DAY',
                        'error': f'Warning: {len(conflict_details_day)} same-day conflict(s).',
                        'conflict_details': conflict_details_day[:15],
                        'can_force': True
                    })
        
        # === ROOM CHECK ===
        if os.path.exists(config_path):
            df_rooms = pd.read_excel(config_path, sheet_name='PhongThi')
            all_rooms = df_rooms['PhongThi'].dropna().astype(str).str.strip().tolist()
        else:
            all_rooms = df_schedule['PhongThi'].unique().tolist()
        
        used_rooms = df_schedule[
            (df_schedule['Ngay'] == target_day) & 
            (df_schedule['Ca'] == target_shift)
        ]['PhongThi'].tolist()
        
        available_rooms = [r for r in all_rooms if r not in used_rooms]
        
        if len(available_rooms) < len(items):
            return jsonify({
                'success': False, 
                'error': f'Not enough rooms. Need {len(items)}, only {len(available_rooms)} available.'
            })
        
        # === UPDATE SCHEDULE ===
        moved_count = 0
        for i, item in enumerate(items):
            idx = df_schedule[
                (df_schedule['MaHP'] == item['MaHP']) & 
                (df_schedule['ToThi'] == item['ToThi'])
            ].index
            
            if len(idx) > 0:
                idx = idx[0]
                df_schedule.at[idx, 'Ngay'] = target_day
                df_schedule.at[idx, 'Ca'] = target_shift
                df_schedule.at[idx, 'PhongThi'] = available_rooms[i]
                moved_count += 1
        
        df_schedule.to_excel(schedule_path, index=False)
        
        # Sync changes to student file
        sync_student_file()
        
        return jsonify({
            'success': True, 
            'message': f'Moved {moved_count} exam group(s) successfully.'
        })

    except Exception as e:
        print(f"Error batch updating schedule: {e}")
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/results', methods=['GET'])
def list_results():
    """Danh s√°ch c√°c file k·∫øt qu·∫£"""
    results = []
    if os.path.exists(RESULT_FOLDER):
        for filename in os.listdir(RESULT_FOLDER):
            if filename.endswith('.xlsx'):
                filepath = os.path.join(RESULT_FOLDER, filename)
                results.append({
                    'filename': filename,
                    'size': os.path.getsize(filepath),
                    'created': datetime.fromtimestamp(os.path.getctime(filepath)).isoformat()
                })
    
    results.sort(key=lambda x: x['created'], reverse=True)
    return jsonify({'success': True, 'results': results})


@app.route('/api/export-students', methods=['POST'])
def export_students():
    """Xu·∫•t file BangTongHopLichThiSinhVien_KetQua.xlsx t·ª´ l·ªãch ƒë√£ ch·ªânh s·ª≠a"""
    try:
        # Paths
        schedule_path = os.path.join(BASE_DIR, 'ket_qua_xep_lich_thi.xlsx')
        sv_path = os.path.join(BASE_DIR, 'danhsachSV.xlsx')
        lhp_path = os.path.join(BASE_DIR, 'danhsachLHP.xlsx')
        config_path = os.path.join(BASE_DIR, 'cau_hinh.xlsx')
        output_path = os.path.join(BASE_DIR, 'BangTongHopLichThiSinhVien_KetQua.xlsx')
        
        # Check files exist
        if not os.path.exists(schedule_path):
            return jsonify({'success': False, 'error': 'Ch∆∞a c√≥ file l·ªãch thi. Vui l√≤ng x·∫øp l·ªãch tr∆∞·ªõc.'})
        if not os.path.exists(sv_path):
            return jsonify({'success': False, 'error': 'Ch∆∞a c√≥ file danhsachSV.xlsx'})
        if not os.path.exists(lhp_path):
            return jsonify({'success': False, 'error': 'Ch∆∞a c√≥ file danhsachLHP.xlsx'})
        
        # Load data
        df_kq = pd.read_excel(schedule_path)
        df_sv = pd.read_excel(sv_path)
        df_lhp = pd.read_excel(lhp_path)
        
        # Normalize MaHP
        df_sv["MaSV"] = df_sv["MaSV"].astype(str).str.strip()
        df_sv["Ten"] = df_sv["Ten"].astype(str).str.strip()
        df_sv["MaHP"] = df_sv["MaHP"].astype(str).str.strip()
        df_kq["MaHP"] = df_kq["MaHP"].astype(str).str.strip()
        df_lhp["MaHP"] = df_lhp["MaHP"].astype(str).str.strip()
        
        # Remove duplicates
        df_sv = df_sv.drop_duplicates(subset=["MaSV", "MaHP"], keep="first")
        
        # Create phong_theo_mon
        phong_theo_mon = df_lhp.set_index("MaHP")[["ToThi"]].to_dict("index")
        
        # Distribute students to ToThi
        ds_sv_to_thi = []
        for mahp, df_mhp in df_sv.groupby("MaHP"):
            if mahp not in phong_theo_mon:
                continue
            so_to = int(phong_theo_mon[mahp]["ToThi"])
            df_mhp_sorted = df_mhp.sort_values("Ten").reset_index(drop=True)
            N = len(df_mhp_sorted)
            if N == 0:
                continue
            base = N // so_to
            du = N % so_to
            start_idx = 0
            for to in range(1, so_to + 1):
                so_sv_to = base + (1 if to <= du else 0)
                df_to = df_mhp_sorted.iloc[start_idx:start_idx + so_sv_to]
                for _, row in df_to.iterrows():
                    ds_sv_to_thi.append({
                        "MaSV": row["MaSV"],
                        "Ten": row["Ten"],
                        "MaHP": mahp,
                        "ToThi": to
                    })
                start_idx += so_sv_to
        
        df_sv_to_thi = pd.DataFrame(ds_sv_to_thi)
        
        # Merge with schedule
        df_final_sv = pd.merge(df_sv_to_thi, df_kq, on=["MaHP", "ToThi"], how="left")
        
        # Add course info
        available_lhp_cols = ["MaHP"]
        if "TenMH" in df_lhp.columns:
            available_lhp_cols.append("TenMH")
        elif "Ten_MH" in df_lhp.columns:
            available_lhp_cols.append("Ten_MH")
        if "SoTC" in df_lhp.columns:
            available_lhp_cols.append("SoTC")
        
        if len(available_lhp_cols) > 1:
            df_lhp_info = df_lhp[available_lhp_cols].drop_duplicates("MaHP")
            df_final_sv = pd.merge(df_final_sv, df_lhp_info, on="MaHP", how="left")
        
        # Add time from Ca
        CA_TO_GIO = {1: "07:00", 2: "09:30", 3: "13:00", 4: "15:30"}
        if "Ca" in df_final_sv.columns:
            df_final_sv["GioThi"] = df_final_sv["Ca"].map(CA_TO_GIO)
        
        # Split Ho Ten
        def tach_ho_ten(full_name):
            if pd.isna(full_name):
                return "", ""
            parts = str(full_name).strip().split()
            if len(parts) == 0:
                return "", ""
            elif len(parts) == 1:
                return "", parts[0]
            else:
                return " ".join(parts[:-1]), parts[-1]
        
        df_final_sv["HoDem"] = df_final_sv["Ten"].apply(lambda x: tach_ho_ten(x)[0])
        df_final_sv["TenSV"] = df_final_sv["Ten"].apply(lambda x: tach_ho_ten(x)[1])
        
        # Rename columns
        rename_dict = {
            "Ten_MH": "T√™n m√¥n", "TenMH": "T√™n m√¥n",
            "SoTC": "S·ªë TC", "MaSV": "M√£ SV",
            "Ngay": "Ng√†y thi", "GioThi": "Gi·ªù thi",
            "PhongThi": "Ph√≤ng thi", "ToThi": "T·ªï thi",
            "HoDem": "H·ªç ƒë·ªám", "TenSV": "T√™n"
        }
        df_final_sv = df_final_sv.rename(columns=rename_dict)
        
        # Add required columns
        df_final_sv["ƒê·ª£t thi"] = "ƒê·ª£t 1"
        df_final_sv["Nh√≥m thi"] = "1"
        df_final_sv["Ghi ch√∫"] = ""
        df_final_sv["M√£ HP"] = df_final_sv["MaHP"]
        
        # Select output columns
        output_cols = [
            "M√£ HP", "T√™n m√¥n", "S·ªë TC", "ƒê·ª£t thi", "Nh√≥m thi", "T·ªï thi",
            "Ng√†y thi", "Gi·ªù thi", "Ph√≤ng thi", "M√£ SV", "H·ªç ƒë·ªám", "T√™n", "Ghi ch√∫"
        ]
        existing_cols = [c for c in output_cols if c in df_final_sv.columns]
        df_final_sv = df_final_sv[existing_cols]
        
        # Remove duplicates
        df_final_sv = df_final_sv.drop_duplicates()
        
        # Export
        df_final_sv.to_excel(output_path, index=False)
        
        return jsonify({
            'success': True,
            'message': f'ƒê√£ xu·∫•t file th√†nh c√¥ng: {len(df_final_sv)} d√≤ng',
            'filename': 'BangTongHopLichThiSinhVien_KetQua.xlsx',
            'rows': len(df_final_sv)
        })
        
    except Exception as e:
        print(f"Error exporting students: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/preview/<file_type>', methods=['GET'])
def preview_file(file_type):
    """Xem tr∆∞·ªõc n·ªôi dung file"""
    import pandas as pd
    
    if file_type not in FILE_TYPES:
        return jsonify({'success': False, 'error': 'Lo·∫°i file kh√¥ng h·ª£p l·ªá'})
    
    filename = FILE_TYPES[file_type]
    filepath = os.path.join(UPLOAD_FOLDER, filename)
    
    if not os.path.exists(filepath):
        return jsonify({'success': False, 'error': 'File ch∆∞a ƒë∆∞·ª£c upload'})
    
    try:
        # ƒê·ªçc file Excel
        if file_type == 'cfg':
            # ƒê·ªçc t·∫•t c·∫£ sheets cho file c·∫•u h√¨nh
            xl = pd.ExcelFile(filepath)
            sheets = {}
            for sheet in xl.sheet_names:
                df = pd.read_excel(filepath, sheet_name=sheet)
                sheets[sheet] = {
                    'columns': df.columns.tolist(),
                    'data': df.head(10).to_dict('records'),
                    'total_rows': len(df)
                }
            return jsonify({
                'success': True,
                'type': 'multi_sheet',
                'sheets': sheets
            })
        else:
            df = pd.read_excel(filepath)
            return jsonify({
                'success': True,
                'type': 'single_sheet',
                'columns': df.columns.tolist(),
                'data': df.head(20).to_dict('records'),
                'total_rows': len(df)
            })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


if __name__ == '__main__':
    print("=" * 50)
    print("üéì X·∫æP L·ªäCH THI - WEB APPLICATION")
    print("=" * 50)
    print(f"üìÅ Upload folder: {UPLOAD_FOLDER}")
    print(f"üìÅ Result folder: {RESULT_FOLDER}")
    print("üåê M·ªü tr√¨nh duy·ªát t·∫°i: http://127.0.0.1:5000")
    print("=" * 50)
    app.run(debug=True, port=5000)
